{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 毕业项目：检测分神司机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir, join, pardir\n",
    "from IPython.display import SVG, Image\n",
    "import os, shutil\n",
    "import random\n",
    "import glob\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from keras import optimizers\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.applications import vgg16\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "\n",
    "import pydot\n",
    "import cv2\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20097 images belonging to 10 classes.\n",
      "Found 2327 images belonging to 10 classes.\n",
      "Found 20097 images belonging to 10 classes.\n",
      "Found 2327 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "vgg16_train_datagen = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input)\n",
    "vgg16_valid_datagen = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input)\n",
    "\n",
    "resnet50_train_datagen = ImageDataGenerator(preprocessing_function=resnet50.preprocess_input)\n",
    "resnet50_valid_datagen = ImageDataGenerator(preprocessing_function=resnet50.preprocess_input)\n",
    "\n",
    "vgg16_train_generator = vgg16_train_datagen.flow_from_directory(\n",
    "    image_train_folder_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical')\n",
    "\n",
    "vgg16_valid_generator = vgg16_valid_datagen.flow_from_directory(\n",
    "    image_valid_folder_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、创建基准模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_model_vgg16():\n",
    "    model_vgg16 = VGG16(include_top=False, weights='imagenet')\n",
    "    \n",
    "    #print('Print vgg16 model summary:')\n",
    "    #print(model_vgg16.summary())\n",
    "    \n",
    "    #for i in range(172):\n",
    "        #model_vgg16.layers[i].trainable = False\n",
    "\n",
    "    input = Input(shape=(224, 224, 3), name='image_input')\n",
    "\n",
    "    output_vgg16_conv = model_vgg16(input)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(output_vgg16_conv)\n",
    "    \n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input, outputs=x)\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=1e-4, momentum=0.9)\n",
    "\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三、基准模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "model_vgg16 = create_model_vgg16()\n",
    "#print('Print my model summry:')\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 五、基准模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1257/1257 [==============================] - 697s 554ms/step - loss: 1.3500 - acc: 0.5207 - val_loss: 0.4976 - val_acc: 0.8638\n",
      "Epoch 2/10\n",
      "1257/1257 [==============================] - 691s 550ms/step - loss: 0.1124 - acc: 0.9675 - val_loss: 0.4437 - val_acc: 0.8436\n",
      "Epoch 3/10\n",
      "1257/1257 [==============================] - 689s 548ms/step - loss: 0.0437 - acc: 0.9875 - val_loss: 0.4160 - val_acc: 0.8672\n",
      "Epoch 4/10\n",
      "1257/1257 [==============================] - 690s 549ms/step - loss: 0.0242 - acc: 0.9926 - val_loss: 0.3902 - val_acc: 0.8629\n",
      "Epoch 5/10\n",
      "1257/1257 [==============================] - 703s 559ms/step - loss: 0.0153 - acc: 0.9957 - val_loss: 0.2946 - val_acc: 0.8917\n",
      "Epoch 6/10\n",
      "1257/1257 [==============================] - 699s 556ms/step - loss: 0.0092 - acc: 0.9974 - val_loss: 0.3535 - val_acc: 0.8762\n",
      "Epoch 7/10\n",
      "1257/1257 [==============================] - 704s 560ms/step - loss: 0.0068 - acc: 0.9979 - val_loss: 0.3836 - val_acc: 0.8608\n",
      "Epoch 8/10\n",
      "1257/1257 [==============================] - 698s 555ms/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.4119 - val_acc: 0.8689\n",
      "Epoch 9/10\n",
      "1257/1257 [==============================] - 708s 563ms/step - loss: 0.0043 - acc: 0.9989 - val_loss: 0.3555 - val_acc: 0.8861\n",
      "Epoch 10/10\n",
      "1257/1257 [==============================] - 697s 555ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.3580 - val_acc: 0.8883\n"
     ]
    }
   ],
   "source": [
    "history_vgg16 = model_vgg16.fit_generator(\n",
    "    vgg16_train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=vgg16_valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vgg16 model saved.\n"
     ]
    }
   ],
   "source": [
    "model_vgg16.save(join(pardir, 'model', 'vgg16.h5'))\n",
    "print(\"Vgg16 model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 六、基准模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n",
      "Model loaded.\n",
      "2492/2492 [==============================] - 819s 328ms/step\n",
      "(79726, 10)\n"
     ]
    }
   ],
   "source": [
    "test_image_path = join(driver_dataset_folder_path, 'test')\n",
    "vgg16_test_datagen = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input)\n",
    "vgg16_test_generator = vgg16_test_datagen.flow_from_directory(\n",
    "    test_image_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical')\n",
    "\n",
    "model_vgg16 = load_model(join(pardir, 'model', 'vgg16.h5'))\n",
    "print(\"Model loaded.\")\n",
    "pred_vgg16 = model_vgg16.predict_generator(vgg16_test_generator, verbose=1)\n",
    "print(pred_vgg16.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 六、生成kaggle提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_names = []\n",
    "for root, dirs, file_name in os.walk(join(test_image_path, '0')):\n",
    "    image_names.append(file_name)\n",
    "image_names = np.array(image_names).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_vgg16 = np.append(image_names, pred_vgg16, axis = 1)\n",
    "predict_result = pd.DataFrame(result_vgg16, \n",
    "            columns=['img', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "predict_result.to_csv('result_vgg16.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
